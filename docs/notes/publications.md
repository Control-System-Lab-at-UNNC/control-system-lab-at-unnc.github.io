---
title: Publications
createTime: 2025/02/12 20:50:41
permalink: /article/publications/
outline:
  - 1
  - 6
---

### 2024

<Publication doi="https://doi.org/10.1109/IROS58592.2024.10801991">

<template #title>

#### Design and Validation of Flexible Aerial Robotics for Safe Human-Robot Interaction

</template>

<template #author>

Jia, Fuhua; Zheng, Zihao; LI, Cheng'ao; Li, Rui; XIAO, Junlin; YANG, Xiaoying; Rushworth, Adam; Ijaz, Salman

</template>

<template #keywords>

<Badge type="info" text="Safety in HRI" />
<Badge type="info" text="Robot Safety" />
<Badge type="info" text="Aerial Systems: Mechanics and Control" />

</template>

<template #abstract>

This work addresses the critical challenge of integrating drones into human-aerial robot interaction by presenting a novel Soft Flexible Aerial Robot (SFAR) design. SFAR features an innovative low-pressure inflatable airbag structure that replaces traditional rigid frames, enhancing safety by mitigating collision risks with humans and payloads. To control this unconventional aerial platform, we present a virtual link dynamics model and a semi-model-based control strategy that exploit the drone's unique design. Our contributions include the pioneering design of an aerial robot specifically for HARI, a novel control framework that balances flight performance with passive safety, and the validation of SFAR through real-world experiments, demonstrating its ability to perform at par with traditional rigid-body drones while offering enhanced safety features for seamless and safe integration into human environments.

</template>

</publication>

<Publication doi="https://doi.org/demo">

<template #title>

#### this is another article

</template>

<template #author>

demo author

</template>

<template #keywords>

<Badge type="info" text="demo" />

</template>

<template #abstract>

demo abstract

</template>

</publication>

<Publication doi="https://doi.org/demo">

<template #title>

#### this is another article

</template>

<template #author>

demo author

</template>

<template #keywords>

<Badge type="info" text="demo" />

</template>

<template #abstract>

demo abstract

</template>

</publication>
<Publication doi="https://doi.org/demo">

<template #title>

#### this is another article

</template>

<template #author>

demo author

</template>

<template #keywords>

<Badge type="info" text="demo" />

</template>

<template #abstract>

demo abstract

</template>

</publication>
<Publication doi="https://doi.org/demo">

<template #title>

#### this is another article

</template>

<template #author>

demo author

</template>

<template #keywords>

<Badge type="info" text="demo" />

</template>

<template #abstract>

demo abstract

</template>

</publication>



### 2022
<Publication doi="https://doi.org/10.3390/polym14102019">

<template #title>

#### Sensors and Sensor Fusion Methodologies for Indoor Odometry: A Review

</template>

<template #author>

Mengshen Yang, Xu Sun, Fuhua Jia, Adam Rushworth, Xin Dong, Sheng Zhang, Zaojun Fang, Guilin Yang, Bingjian Liu

</template>

<template #keywords>

<Badge type="info" text="IMU" />
<Badge type="info" text="LiDAR" />
<Badge type="info" text="SLAM" />
<Badge type="info" text="camera" />
<Badge type="info" text="odometry" />
<Badge type="info" text="polymeric sensor" />
<Badge type="info" text="radar" />
<Badge type="info" text="self-contained localization" />
<Badge type="info" text="sensor fusion" />
<Badge type="info" text="state estimation" />

</template>

<template #abstract>

Although Global Navigation Satellite Systems (GNSSs) generally provide adequate accuracy for outdoor localization, this is not the case for indoor environments, due to signal obstruction. Therefore, a self-contained localization scheme is beneficial under such circumstances. Modern sensors and algorithms endow moving robots with the capability to perceive their environment, and enable the deployment of novel localization schemes, such as odometry, or Simultaneous Localization and Mapping (SLAM). The former focuses on incremental localization, while the latter stores an interpretable map of the environment concurrently. In this context, this paper conducts a comprehensive review of sensor modalities, including Inertial Measurement Units (IMUs), Light Detection and Ranging (LiDAR), radio detection and ranging (radar), and cameras, as well as applications of polymers in these sensors, for indoor odometry. Furthermore, analysis and discussion of the algorithms and the fusion frameworks for pose estimation and odometry with these sensors are performed. Therefore, this paper straightens the pathway of indoor odometry from principle to application. Finally, some future prospects are discussed.
</template>

</publication>